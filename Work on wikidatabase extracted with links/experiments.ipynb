{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(article):\n",
    "    stopword_list = set(stopwords.words(\"english\"))\n",
    "    return [word for word in article.split() if word not in stopword_list]\n",
    "\n",
    "\n",
    "def remove_character(article):\n",
    "    return re.sub(\"[^a-zA-Z]+\", \" \", article)\n",
    "\n",
    "\n",
    "def lower(string):\n",
    "    return string.lower()\n",
    "\n",
    "\n",
    "def clean(article):\n",
    "    article = article.strip()\n",
    "    article = lower(article)\n",
    "    article = remove_character(article)\n",
    "    article = remove_stopwords(article)\n",
    "    article = ' '.join(article)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_count_vec(max_n_word=20000,mode_tfidf = True) : \n",
    "    \n",
    "    text_train = []\n",
    "    target_train = []\n",
    "    text_val = []\n",
    "    target_val = []\n",
    "    text_test = []\n",
    "    target_test = []   \n",
    "    \n",
    "    print('Loading and cleaning files ...')\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    for link in glob.glob('/Users/andrealequin/Desktop/Stage_NLP/Simple_extraction/train_list/*.txt') : \n",
    "        file = open(link,'r')\n",
    "        text_train.append(clean(file.read()))\n",
    "        target_train.append(int(os.path.basename(file.name)[0:2]))\n",
    "\n",
    "        \n",
    "    for link in glob.glob('/Users/andrealequin/Desktop/Stage_NLP/Simple_extraction/val_list/*.txt') : \n",
    "        file = open(link,'r')\n",
    "        text_val.append(clean(file.read()))\n",
    "        target_val.append(int(os.path.basename(file.name)[0:2]))   \n",
    "\n",
    "    for link in glob.glob('/Users/andrealequin/Desktop/Stage_NLP/Simple_extraction/test_list/*.txt') : \n",
    "        file = open(link,'r')\n",
    "        text_test.append(clean(file.read()))\n",
    "        target_test.append(int(os.path.basename(file.name)[0:2]))   \n",
    "        \n",
    "    t1 = time.time()\n",
    "    \n",
    "    print('Loading and cleaning files time : ', t1-t0)\n",
    "    \n",
    "    print('Count Vectorization ...')\n",
    "    \n",
    "    if mode_tfidf == True : \n",
    "        vectorizer = TfidfVectorizer(max_features = max_n_word)\n",
    "        print('mode : tdidf')\n",
    "    else : \n",
    "        vectorizer = CountVectorizer(max_features = max_n_word)\n",
    "        print('mode : simple count')\n",
    "        \n",
    "    x_train = vectorizer.fit_transform(text_train)\n",
    "    y_train = np.asarray(target_train)\n",
    "  \n",
    "    x_val = vectorizer.transform(text_val)\n",
    "    y_val = np.asarray(target_val)\n",
    "    \n",
    "    x_test = vectorizer.transform(text_test)\n",
    "    y_test = np.asarray(target_test)\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print('Vectorization time : ', t2-t1)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test, text_train, text_val, text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and cleaning files ...\n",
      "Loading and cleaning files time :  37.14863896369934\n",
      "Count Vectorization ...\n",
      "mode : tdidf\n",
      "Vectorization time :  19.42878794670105\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test, text_train, text_val, text_test = create_input_count_vec(max_n_word=20000,mode_tfidf = True)\n",
    "sets = x_train, y_train, x_val, y_val, x_test, y_test, text_train, text_val, text_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logreg(sets) :\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test, text_train, text_val, text_test = sets\n",
    "    print('Build logistic regression model ...')\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_train)\n",
    "    acc = accuracy_score(y_train, y_pred)\n",
    "    y_pred = clf.predict(x_val)\n",
    "    val_acc = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    print('acc :', acc)\n",
    "    print('val acc :', val_acc)\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    \n",
    "    return #clf.predict_proba(np.concatenate((x_train, x_val), axis=0))[:, 1], \\\n",
    "           #clf.predict_proba(x_test)[:, 1], \\\n",
    "           #np.concatenate((y_train, y_val), axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build logistic regression model ...\n",
      "acc : 0.9295279912184413\n",
      "val acc : 0.857703081232493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       400\n",
      "           1       0.88      0.92      0.90       400\n",
      "           2       0.88      0.79      0.83       185\n",
      "           3       0.82      0.86      0.84       400\n",
      "           4       0.79      0.79      0.79       400\n",
      "\n",
      "    accuracy                           0.86      1785\n",
      "   macro avg       0.86      0.85      0.85      1785\n",
      "weighted avg       0.86      0.86      0.86      1785\n",
      "\n",
      "[[359   4   0  19  18]\n",
      " [  3 369   1   9  18]\n",
      " [  1   2 146  20  16]\n",
      " [  7   4  12 343  34]\n",
      " [ 13  40   7  26 314]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "run_logreg(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm(sets): \n",
    "    x_train, y_train, x_val, y_val, x_test, y_test, text_train, text_val, text_test = sets\n",
    "    print('Build SVM model ...')\n",
    "    #[x_train, y_train, x_val, y_val, x_test, y_test] = pickle.load(open('/Users/andrealequin/Desktop/Stage_NLP/Simple_extraction/dumps/'+str(num_set)+'.dat', \"rb\"))\n",
    "    svm = LinearSVC(C=0.0001)\n",
    "    svm = CalibratedClassifierCV(svm)\n",
    "    svm.fit(x_train, y_train)\n",
    "    y_pred = svm.predict(x_train)\n",
    "    acc = accuracy_score(y_train, y_pred)\n",
    "    y_pred = svm.predict(x_val)\n",
    "    val_acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    print('acc :', acc)\n",
    "    print('val acc :', val_acc)\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    return #svm.predict_proba(np.concatenate((x_train, x_val), axis=0))[:, 1], \\\n",
    "           #svm.predict_proba(x_test)[:, 1], \\\n",
    "           #np.concatenate((y_train, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build SVM model ...\n",
      "acc : 0.8384193194291987\n",
      "val acc : 0.8212885154061624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88       400\n",
      "           1       0.84      0.91      0.87       400\n",
      "           2       0.82      0.77      0.79       185\n",
      "           3       0.81      0.80      0.80       400\n",
      "           4       0.71      0.77      0.74       400\n",
      "\n",
      "    accuracy                           0.82      1785\n",
      "   macro avg       0.83      0.82      0.82      1785\n",
      "weighted avg       0.83      0.82      0.82      1785\n",
      "\n",
      "[[334   5   1  28  32]\n",
      " [  3 362   2   9  24]\n",
      " [  1   3 142  20  19]\n",
      " [  4   8  19 321  48]\n",
      " [ 13  51   9  20 307]]\n"
     ]
    }
   ],
   "source": [
    "run_svm(sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RandomForest(sets):\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test, text_train, text_val, text_test = sets\n",
    "    print('Build Random Forest model ...')\n",
    "    #[x_train, y_train, x_val, y_val, x_test, y_test] = pickle.load(open('/Users/andrealequin/Desktop/Stage_NLP/Simple_extraction/dumps/'+str(num_set)+'.dat', \"rb\"))\n",
    "    clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_train)\n",
    "    acc = accuracy_score(y_train, y_pred)\n",
    "    y_pred = clf.predict(x_val)\n",
    "    val_acc = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    print('acc :', acc)\n",
    "    print('val acc :', val_acc)\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    \n",
    "    return #clf.predict_proba(np.concatenate((x_train, x_val), axis=0))[:, 1], \\\n",
    "           #clf.predict_proba(x_test)[:, 1], \\\n",
    "           #np.concatenate((y_train, y_val), axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Random Forest model ...\n",
      "acc : 0.7054884742041713\n",
      "val acc : 0.6868347338935574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       400\n",
      "           1       0.75      0.89      0.82       400\n",
      "           2       1.00      0.01      0.01       185\n",
      "           3       0.55      0.80      0.65       400\n",
      "           4       0.61      0.51      0.56       400\n",
      "\n",
      "    accuracy                           0.69      1785\n",
      "   macro avg       0.76      0.61      0.58      1785\n",
      "weighted avg       0.73      0.69      0.65      1785\n",
      "\n",
      "[[345  10   0  29  16]\n",
      " [  3 355   0  30  12]\n",
      " [  4   5   1 116  59]\n",
      " [ 21  14   0 320  45]\n",
      " [ 24  87   0  84 205]]\n"
     ]
    }
   ],
   "source": [
    "run_RandomForest(sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(text_train)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(text_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:541 train_step  **\n        self.trainable_variables)\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1804 _minimize\n        trainable_variables))\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:521 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1219 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['Variable:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d44f37b0038d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:541 train_step  **\n        self.trainable_variables)\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1804 _minimize\n        trainable_variables))\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:521 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    /Users/andrealequin/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1219 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['Variable:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0'].\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset.shuffle(10000).batch(512),\n",
    "                    epochs=20,\n",
    "                    validation_data=val_dataset.batch(512),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 254729 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower= True)\n",
    "tokenizer.fit_on_texts(text_train)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (12680, 100)\n",
      "Shape of label tensor: (12680, 5)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(text_train+text_val+text_test)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "Y = pd.get_dummies(np.concatenate((y_train,y_val,y_test))).values\n",
    "print('Shape of data tensor:', X.shape)\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11412, 100) (11412, 5)\n",
      "(1268, 100) (1268, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]]\n",
      "[[    0     0     0 ...   208   235   668]\n",
      " [ 9341   754   614 ...  3867  1496   513]\n",
      " [   56  8459  2581 ... 15163 23410   163]\n",
      " ...\n",
      " [10050   152  2014 ...  3340 33373   415]\n",
      " [  147    72    59 ...    91  1258 25820]\n",
      " [14925  6182  1481 ...  1481   442 19636]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[:10])\n",
    "print(X_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 5,080,905\n",
      "Trainable params: 5,080,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 100, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 100, 20)           8880      \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 20)                2480      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,011,465\n",
      "Trainable params: 5,011,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(5, 10)))\n",
    "model.add(Bidirectional(LSTM(10)))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer lstm_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 20]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-44b495765ca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#model.add(tf.keras.layers.SpatialDropout1D(0.2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 886\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    887\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[1;32m    888\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
      "\u001b[0;32m~/anaconda/envs/envtf/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer lstm_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 20]"
     ]
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "\n",
    "#model = Sequential()\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.SpatialDropout1D(0.2))\n",
    "model.add(tf.keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10270 samples, validate on 1142 samples\n",
      "Epoch 1/20\n",
      "10270/10270 [==============================] - 19s 2ms/step - loss: 0.2146 - accuracy: 0.8863 - val_loss: 3.2340 - val_accuracy: 0.2531\n",
      "Epoch 2/20\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.2114 - accuracy: 0.8873 - val_loss: 3.2926 - val_accuracy: 0.2592\n",
      "Epoch 3/20\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.2078 - accuracy: 0.8879 - val_loss: 3.3671 - val_accuracy: 0.2539\n",
      "Epoch 4/20\n",
      "10270/10270 [==============================] - 19s 2ms/step - loss: 0.2048 - accuracy: 0.8861 - val_loss: 3.4387 - val_accuracy: 0.2513\n",
      "Epoch 5/20\n",
      "10270/10270 [==============================] - 16s 2ms/step - loss: 0.2031 - accuracy: 0.8870 - val_loss: 3.4128 - val_accuracy: 0.2583\n",
      "Epoch 6/20\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.2007 - accuracy: 0.8878 - val_loss: 3.4222 - val_accuracy: 0.2601\n",
      "Epoch 7/20\n",
      "10270/10270 [==============================] - 15s 1ms/step - loss: 0.2010 - accuracy: 0.8865 - val_loss: 3.4790 - val_accuracy: 0.2557\n",
      "Epoch 8/20\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.2001 - accuracy: 0.8893 - val_loss: 3.4831 - val_accuracy: 0.2653\n",
      "Epoch 9/20\n",
      "10270/10270 [==============================] - 18s 2ms/step - loss: 0.1979 - accuracy: 0.8864 - val_loss: 3.5545 - val_accuracy: 0.2636\n",
      "Epoch 10/20\n",
      "10270/10270 [==============================] - 18s 2ms/step - loss: 0.1954 - accuracy: 0.8887 - val_loss: 3.5736 - val_accuracy: 0.2680\n",
      "Epoch 11/20\n",
      "10270/10270 [==============================] - 15s 1ms/step - loss: 0.1955 - accuracy: 0.8887 - val_loss: 3.5608 - val_accuracy: 0.2592\n",
      "Epoch 12/20\n",
      "10270/10270 [==============================] - 14s 1ms/step - loss: 0.1939 - accuracy: 0.8907 - val_loss: 3.6030 - val_accuracy: 0.2636\n",
      "Epoch 13/20\n",
      "10270/10270 [==============================] - 14s 1ms/step - loss: 0.1939 - accuracy: 0.8876 - val_loss: 3.5606 - val_accuracy: 0.2601\n",
      "Epoch 14/20\n",
      "10270/10270 [==============================] - 14s 1ms/step - loss: 0.1922 - accuracy: 0.8898 - val_loss: 3.6605 - val_accuracy: 0.2671\n",
      "Epoch 15/20\n",
      "10270/10270 [==============================] - 14s 1ms/step - loss: 0.1924 - accuracy: 0.8886 - val_loss: 3.6694 - val_accuracy: 0.2636\n",
      "Epoch 16/20\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.1915 - accuracy: 0.8868 - val_loss: 3.6621 - val_accuracy: 0.2566\n",
      "Epoch 17/20\n",
      "10270/10270 [==============================] - 15s 1ms/step - loss: 0.1886 - accuracy: 0.8881 - val_loss: 3.7052 - val_accuracy: 0.2592\n",
      "Epoch 18/20\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.1877 - accuracy: 0.8872 - val_loss: 3.7246 - val_accuracy: 0.2767\n",
      "Epoch 19/20\n",
      "10270/10270 [==============================] - 18s 2ms/step - loss: 0.1872 - accuracy: 0.8893 - val_loss: 3.7503 - val_accuracy: 0.2609\n",
      "Epoch 20/20\n",
      "10270/10270 [==============================] - 17s 2ms/step - loss: 0.1870 - accuracy: 0.8887 - val_loss: 3.7640 - val_accuracy: 0.2785\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 256\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=20, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911/911 [==============================] - 2s 2ms/step\n",
      "Test set\n",
      "  Loss: 2.092\n",
      "  Accuracy: 0.215\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
